Twitter Sentiment Analysis avec PySpark ğŸš€

Un pipeline Big Data complet pour l'analyse de sentiment en temps rÃ©el sur des flux de tweets, utilisant Apache Spark Structured Streaming et l'algorithme Naive Bayes.

ğŸ— Architecture du Projet

Le projet suit une architecture Lambda simplifiÃ©e pour le traitement en temps rÃ©el :

Ingestion & Training : Le modÃ¨le est entraÃ®nÃ© sur le dataset Sentiment140 (1.6 millions de tweets) via Spark MLlib.

Producer (Simulation) : Un script Python simule un flux de donnÃ©es en direct via des Sockets TCP.

Processor (Streaming) : Spark Structured Streaming charge le modÃ¨le entraÃ®nÃ©, Ã©coute le flux, prÃ©dit le sentiment (Positif/NÃ©gatif) et affiche le rÃ©sultat en temps rÃ©el.

ğŸ“‚ Structure du Projet

Twitter_sentiment_analysis/
â”œâ”€â”€ data/               # Dossier pour les datasets (non inclus sur GitHub)
â”œâ”€â”€ models/             # Dossier de sauvegarde du modÃ¨le Pipeline
â”œâ”€â”€ notebooks/          # Scripts d'entraÃ®nement et notebooks
â”‚   â””â”€â”€ training.py     # Script principal pour entraÃ®ner et sauvegarder le modÃ¨le
â”œâ”€â”€ src/                # Code source de l'application
â”‚   â”œâ”€â”€ producer.py     # Serveur Socket qui envoie les tweets (Simulation)
â”‚   â”œâ”€â”€ processor.py    # Client Spark Streaming qui prÃ©dit les sentiments
â”‚   â””â”€â”€ evaluate_model.py # Script de validation de l'accuracy
â”œâ”€â”€ .gitignore          # Fichiers Ã  ignorer par Git
â”œâ”€â”€ requirements.txt    # Liste des dÃ©pendances Python
â””â”€â”€ README.md           # Documentation du projet


ğŸ›  PrÃ©requis

Python 3.12 (ou supÃ©rieur)

Java 17 (OpenJDK) : Indispensable pour Spark.

Apache Spark 3.x

WSL2 (si vous Ãªtes sous Windows)

ğŸ“¦ Installation

1. Cloner le projet

git clone [https://github.com/VOTRE_USER/Twitter_sentiment_analysis.git](https://github.com/VOTRE_USER/Twitter_sentiment_analysis.git)
cd Twitter_sentiment_analysis


2. CrÃ©er l'environnement virtuel

python3 -m venv .venv
source .venv/bin/activate


3. Installer les dÃ©pendances

pip install -r requirements.txt


ğŸš€ Utilisation

1. EntraÃ®nement du ModÃ¨le

Avant de lancer le streaming, il est impÃ©ratif de gÃ©nÃ©rer le modÃ¨le (Pipeline Naive Bayes) qui sera sauvegardÃ© dans le dossier models/.

# Ce script tÃ©lÃ©charge les donnÃ©es (si nÃ©cessaire) et entraÃ®ne le modÃ¨le
python3 notebooks/training.py


Note : L'accuracy attendue est d'environ 77-78%.

2. Validation (Optionnel)

Pour vÃ©rifier la prÃ©cision du modÃ¨le sur des donnÃ©es de test :

python3 src/evaluate_model.py


3. Lancer le Streaming

Vous devez ouvrir deux terminaux sÃ©parÃ©s (et activer l'environnement virtuel dans les deux).

Terminal 1 : Le Producteur (Serveur)
Il va lire les donnÃ©es de test et les envoyer sur le port 9999.

source .venv/bin/activate
python3 src/producer.py


Attendez de voir le message : "En attente de la connexion de Spark..."

Terminal 2 : Le Processeur (Spark Streaming)
Il Ã©coute le port 9999, charge le modÃ¨le et prÃ©dit en direct.

source .venv/bin/activate
python3 src/processor.py


ğŸ“Š RÃ©sultats

Une fois connectÃ©s, le processeur affichera les prÃ©dictions par batch toutes les 2 secondes :

-------------------------------------------
Batch: 5
-------------------------------------------
+-----------------------+-----------+
|text                   |sentiment  |
+-----------------------+-----------+
|I love this project!   |ğŸ˜ƒ Positif |
|My code is broken...   |ğŸ˜¡ NÃ©gatif |
+-----------------------+-----------+


ğŸ‘¤ Auteur

Aboubakr Tahir

Ã‰tudiant IngÃ©nieur en Big Data & Cloud Computing

ENSA Berrechid, Maroc