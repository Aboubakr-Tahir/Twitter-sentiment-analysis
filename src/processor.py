import sys
import os

# Configuration de l'environnement (au cas oÃ¹)
os.environ['PYSPARK_PYTHON'] = sys.executable
os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable

from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.functions import col, udf
from pyspark.sql.types import StringType

# 1. Initialisation de la Session Spark
print("ðŸš€ DÃ©marrage du moteur Spark Streaming...")
spark = SparkSession.builder \
    .appName("TwitterSentimentAnalysis_RealTime") \
    .config("spark.driver.memory", "4g") \
    .config("spark.sql.shuffle.partitions", "2") \
    .getOrCreate()

# RÃ©duire le bruit dans les logs
spark.sparkContext.setLogLevel("WARN")

# 2. Chemins
base_path = "/home/aboubakr/projects/Twitter_sentiment_analysis"
model_path = f"{base_path}/models/naive_bayes_sentiment"

# 3. Chargement du Pipeline EntraÃ®nÃ©
print(f"â³ Chargement du modÃ¨le depuis : {model_path}")
try:
    # On charge le PipelineModel car il contient le StringIndexer et le Tokenizer
    loaded_pipeline = PipelineModel.load(model_path)
    print("âœ… ModÃ¨le chargÃ© avec succÃ¨s !")
except Exception as e:
    print(f"âŒ ERREUR CRITIQUE : Impossible de charger le modÃ¨le.\n{e}")
    sys.exit(1)

# 4. Connexion au flux (Socket)
print("ðŸ“¡ Tentative de connexion au Producer sur localhost:9999...")

# Spark lit le flux ligne par ligne. La colonne s'appelle par dÃ©faut "value".
raw_stream = spark.readStream \
    .format("socket") \
    .option("host", "localhost") \
    .option("port", 9999) \
    .load()

# IMPORTANT : Le modÃ¨le attend une colonne nommÃ©e "text" (comme lors de l'entraÃ®nement)
# On renomme "value" -> "text"
tweet_stream = raw_stream.select(col("value").alias("text"))

# 5. PrÃ©diction en Temps RÃ©el
# Le pipeline fait tout : Tokenization -> HashingTF -> Classification
predictions = loaded_pipeline.transform(tweet_stream)

# 6. Embellissement du rÃ©sultat (Mapping 0.0 -> NÃ©gatif, 1.0 -> Positif)
# Rappel : StringIndexer a transformÃ© 0->0.0 (NÃ©gatif) et 4->1.0 (Positif)
def map_label(prediction):
    if prediction == 1.0:
        return "ðŸ˜ƒ Positif"
    else:
        return "ðŸ˜¡ NÃ©gatif"

# On enregistre cette fonction pour que Spark puisse l'utiliser (UDF)
label_udf = udf(map_label, StringType())

# SÃ©lection finale pour l'affichage
final_output = predictions.select(
    col("text"),
    label_udf(col("prediction")).alias("sentiment"),
    col("probability")
)

# 7. Affichage dans la console
# Trigger "processingTime='2 seconds'" pour mettre Ã  jour l'affichage toutes les 2s
print("ðŸŽ¬ Streaming lancÃ© ! Regardez les prÃ©dictions dÃ©filer ci-dessous :")
print("---------------------------------------------------------------")

query = final_stream = final_output.writeStream \
    .outputMode("append") \
    .format("console") \
    .option("truncate", "false") \
    .trigger(processingTime="2 seconds") \
    .start()

query.awaitTermination()